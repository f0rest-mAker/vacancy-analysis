{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0688e3b-6749-4194-b348-351eaac9827a",
   "metadata": {},
   "source": [
    "## Импорт и инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77480870-1354-43f5-b5cc-0be0b12e0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import html\n",
    "import time\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "import string\n",
    "from geopy.geocoders import Nominatim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Tuple, Dict\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41c28c5-8f0a-42dd-9bf1-9c1e5d4174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    port=5433,\n",
    "    user='postgres',\n",
    "    password='1029384756',\n",
    "    dbname='vacancy_analysis'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "currency_TOKEN = \"928dce37a9934ff99994af3d811c448e\"\n",
    "currency_values = requests.get(f\"https://api.currencyfreaks.com/v2.0/rates/latest?apikey={currency_TOKEN}\").json()[\"rates\"]\n",
    "\n",
    "loc = Nominatim(user_agent=\"GetLoc\")\n",
    "\n",
    "def convert_with_checking(func, dict, target):\n",
    "    '''\n",
    "        Функция конертации с проверкой на наличие поля в json\n",
    "    '''\n",
    "    if dict:\n",
    "        value = dict[target]\n",
    "        if value:\n",
    "            return func(value)\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_to_RUB(value, from_currency):\n",
    "    RUB_value = float(currency_values[\"RUB\"])\n",
    "    from_currency_value = float(currency_values[from_currency])\n",
    "    to_USD = value / from_currency_value\n",
    "    return int(to_USD * RUB_value)\n",
    "\n",
    "\n",
    "def get_proper_skill_getmatch(skill_tag):\n",
    "    result = []\n",
    "    splitted = [word.strip() for word in skill_tag.split(\"/\")]\n",
    "    i = 0\n",
    "    changed = False\n",
    "    while i != len(splitted):\n",
    "        if splitted[i].isdigit():\n",
    "            if not(changed) and result:\n",
    "                result[-1] = re.sub(r'\\d+$', '', result[-1]).strip()\n",
    "                changed = True\n",
    "        else:\n",
    "            if len(splitted[i]) <= 45:\n",
    "                result.append(splitted[i])\n",
    "                changed = False\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_requirements_segment(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Удалим скрипты, стили и ненужное\n",
    "    for tag in soup(['script', 'style']):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator='\\n')\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    # Ключевые маркеры начала требований\n",
    "    requirement_headers = [\n",
    "        r'Требования',\n",
    "        r'Что мы ожидаем',\n",
    "        r'Что ты умеешь',\n",
    "        r'Нам нужен',\n",
    "        r'Подойдет кандидат',\n",
    "        r'Ожидания',\n",
    "        r'Что нам важно',\n",
    "        r'Технические навыки',\n",
    "        r'Ваш опыт'\n",
    "    ]\n",
    "    pattern = re.compile('|'.join(requirement_headers))\n",
    "\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "\n",
    "    # Найдём начало сегмента\n",
    "    for i, line in enumerate(lines):\n",
    "        if pattern.search(line):\n",
    "            start_idx = i\n",
    "            break\n",
    "\n",
    "    if start_idx is not None:\n",
    "        # Ограничим до следующего заголовка (условия, задачи, мы предлагаем и т.п.)\n",
    "        end_headers = [\n",
    "            r'Обязанности',\n",
    "            r'Что делать',\n",
    "            r'Условия',\n",
    "            r'Предлагаем',\n",
    "            r'Компания',\n",
    "            r'О нас',\n",
    "            r'Контакты',\n",
    "            r'Офис',\n",
    "            r'Зарплата',\n",
    "            r'Преимущества'\n",
    "        ]\n",
    "        end_pattern = re.compile('|'.join(end_headers))\n",
    "\n",
    "        for j in range(start_idx + 1, len(lines)):\n",
    "            if end_pattern.search(lines[j]):\n",
    "                end_idx = j\n",
    "                break\n",
    "\n",
    "        selected = lines[start_idx:end_idx] if end_idx else lines[start_idx:]\n",
    "        return ' '.join(selected)\n",
    "    \n",
    "    return ' '.join(lines[5:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6229c7f-97f9-4bd8-a996-c8174c6b937d",
   "metadata": {},
   "source": [
    "## Парсинг технических навыков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624f637a-267f-49e0-b5f1-99bd3735abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"select id, name from skills\")\n",
    "tech_skills = dict([(name, id) for id, name in cursor.fetchall()])\n",
    "skills = set(tech_skills.keys())\n",
    "parsing_skills = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd395f0e-bf6c-4545-9b8a-8c62a543ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "# Парсинг Habr career\n",
    "i = 1\n",
    "while True:\n",
    "    habr_response = requests.get(f\"https://career.habr.com/vacancies?page={i}&s[]=22&s[]=17&s[]=18&s[]=183&s[]=19&s[]=187&s[]=20&s[]=89&s[]=108&s[]=129&s[]=130&s[]=51&s[]=52&s[]=53&s[]=102&s[]=103&s[]=104&s[]=120&s[]=121&s[]=113&s[]=132&s[]=131&s[]=179&s[]=49&s[]=45&s[]=46&s[]=50&s[]=47&s[]=48&s[]=101&s[]=112&s[]=44&s[]=125&s[]=177&s[]=175&s[]=126&s[]=78&s[]=21&s[]=172&s[]=174&s[]=79&s[]=173&s[]=80&s[]=176&s[]=81&s[]=118&s[]=182&s[]=32&s[]=33&s[]=34&s[]=119&s[]=185&s[]=36&s[]=186&s[]=37&s[]=110&s[]=94&s[]=23&s[]=24&s[]=30&s[]=25&s[]=27&s[]=26&s[]=90&s[]=28&s[]=91&s[]=92&s[]=29&s[]=93&s[]=122&s[]=31&s[]=109&s[]=98&s[]=41&s[]=42&s[]=43&s[]=168&s[]=99&s[]=76&s[]=96&s[]=97&s[]=95&s[]=100&s[]=133&s[]=111&s[]=12&s[]=10&s[]=13&s[]=87&s[]=11&s[]=14&s[]=15&s[]=16&s[]=107&s[]=2&s[]=3&s[]=4&s[]=82&s[]=72&s[]=5&s[]=75&s[]=6&s[]=1&s[]=77&s[]=7&s[]=83&s[]=84&s[]=73&s[]=8&s[]=85&s[]=86&s[]=188&s[]=178&s[]=106&type=all\")\n",
    "    soup = BeautifulSoup(habr_response.text, 'html.parser')\n",
    "    tags = soup.select('.vacancy-card__skills a')\n",
    "    if not tags:\n",
    "        break\n",
    "    for tag in tags:\n",
    "        parsing_skills.add(tag.text.strip().lower())\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c03864-6417-4abd-b1ae-f1a304f9b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 done\n",
      "20 done\n",
      "30 done\n",
      "40 done\n",
      "50 done\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "# Парсинг getmatch\n",
    "response = requests.get(\"https://getmatch.ru/vacancies?p=1&sa=150000&pa=all&s=landing_ca_vacancies\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "pages = []\n",
    "for page_num in soup.find_all(class_='b-pagination-page ng-star-inserted'):\n",
    "    if (num := page_num.text.strip()).isdigit(): pages.append(int(num))\n",
    "max_page = max(pages)\n",
    "\n",
    "for page in range(1, max_page+1):\n",
    "    response = requests.get(f\"https://getmatch.ru/vacancies?p={page}&sa=150000&pa=all&s=landing_ca_vacancies\")\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    for skill_tag in soup.select('div.b-vacancy-card-subtitle__stack span'):\n",
    "        if (lowered_tag := skill_tag.text.strip().lower()) in skills: continue\n",
    "        for skill in get_proper_skill_getmatch(re.sub(r\"\\([\\w\\W]+\\)\", '', lowered_tag)):\n",
    "            parsing_skills.add(skill.strip())\n",
    "    if page % 10 == 0:\n",
    "        print(f\"{page} done\")\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7ef89-dfa8-4ceb-9073-6dab4fcf82de",
   "metadata": {},
   "source": [
    "## Обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe5ea17-a0f6-4261-97c7-8088d6be1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM roles\")\n",
    "roles = dict([(row[0], row[1]) for row in cursor.fetchall()])\n",
    "all_roles_id = roles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23c35b-0f74-4fcc-9eca-4a691a12a23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_vacancies = []\n",
    "try:\n",
    "    for id in all_roles_id:\n",
    "        vacancies = []\n",
    "        i = 0\n",
    "        response = requests.get(f\"https://api.hh.ru/vacancies?area=113&per_page=100&page={i}&order_by=publication_time&ored_clusters=true&professional_role={id}&period=1\")\n",
    "        response_data = response.json()\n",
    "        print(f\"{roles[id]}: {response.status_code}, {response.reason}, {response_data['found']}\")\n",
    "        vacancies += response_data[\"items\"]\n",
    "        if to := response_data[\"found\"] // 100:\n",
    "            for i in range(1, to + 1):\n",
    "                response = requests.get(f\"https://api.hh.ru/vacancies?area=113&per_page=100&page={i}&order_by=publication_time&ored_clusters=true&professional_role={id}&period=1\").json()\n",
    "                vacancies += response[\"items\"]\n",
    "        all_vacancies.append({\"role_id\": id, \"vacancies\": vacancies})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280dbff-f67f-4e62-b481-80737c141f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = {\"items\": all_vacancies}\n",
    "with open(\"json_results/data.json\", 'w', encoding='utf-16') as file:\n",
    "    json.dump(to_dump, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c4fc35-ec86-4cbd-b528-e30171946606",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"json_results/data.json\", 'r', encoding='utf-16').read()\n",
    "data = json.loads(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85aaec25-fee1-4691-bf19-4ea52bc153ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "vacancy_data = []\n",
    "vacancy_role = []\n",
    "vacancy_work_formats = []\n",
    "employers = {}\n",
    "i = 0\n",
    "for role_data in data[\"items\"]:\n",
    "    for vacancy in role_data[\"vacancies\"]:\n",
    "        if not(\"id\" in vacancy[\"employer\"]): continue\n",
    "        \n",
    "        salary_from = convert_with_checking(int, vacancy[\"salary_range\"], \"from\")\n",
    "        salary_to = convert_with_checking(int, vacancy[\"salary_range\"], \"to\")\n",
    "\n",
    "        if vacancy[\"salary_range\"] and (currency := vacancy[\"salary_range\"][\"currency\"]) != \"RUR\":\n",
    "            if salary_from: salary_from = convert_to_RUB(salary_from, currency)\n",
    "            if salary_to: salary_to = convert_to_RUB(salary_to, currency)\n",
    "        \n",
    "        vacancy_data.append([\n",
    "            int(vacancy[\"id\"]),\n",
    "            vacancy[\"area\"][\"name\"],\n",
    "            convert_with_checking(float, vacancy[\"address\"], \"lat\"),\n",
    "            convert_with_checking(float, vacancy[\"address\"], \"lng\"),\n",
    "            vacancy[\"archived\"],\n",
    "            datetime.fromisoformat(vacancy[\"created_at\"]),\n",
    "            datetime.fromisoformat(vacancy[\"published_at\"]),\n",
    "            vacancy[\"has_test\"],\n",
    "            vacancy[\"internship\"],\n",
    "            salary_from,\n",
    "            salary_to,\n",
    "            vacancy[\"salary_range\"][\"frequency\"][\"name\"].replace('\\xa0', ' ') if vacancy[\"salary_range\"] and vacancy[\"salary_range\"][\"frequency\"] else \"Неизвестно\",\n",
    "            int(vacancy[\"employer\"][\"id\"]),\n",
    "            vacancy[\"experience\"][\"name\"],\n",
    "            vacancy[\"employment\"][\"name\"]\n",
    "        ])\n",
    "        \n",
    "        vacancy_role.append([\n",
    "            int(vacancy[\"id\"]),\n",
    "            role_data[\"role_id\"]\n",
    "        ])\n",
    "        \n",
    "        vacancy_work_formats += [\n",
    "            [int(vacancy[\"id\"]), work_format[\"name\"].replace(\"\\xa0\", \" \")]\n",
    "            for work_format in vacancy[\"work_format\"]\n",
    "        ]\n",
    "                    \n",
    "        employer = employers.get(vacancy[\"employer\"][\"id\"], [])\n",
    "        if not employer:\n",
    "            employers[int(vacancy[\"employer\"][\"id\"])] = [\n",
    "                vacancy[\"employer\"][\"name\"],\n",
    "                None if not(\"employer_rating\" in vacancy[\"employer\"]) else convert_with_checking(float, vacancy[\"employer\"][\"employer_rating\"], \"total_rating\"),\n",
    "                None if not(\"employer_rating\" in vacancy[\"employer\"]) else convert_with_checking(int, vacancy[\"employer\"][\"employer_rating\"], \"reviews_count\"),\n",
    "                vacancy[\"employer\"][\"accredited_it_employer\"],\n",
    "                vacancy[\"employer\"][\"trusted\"],\n",
    "                vacancy[\"employer\"][\"logo_urls\"][\"original\"] if vacancy[\"employer\"][\"logo_urls\"] else None\n",
    "            ]\n",
    "        else:\n",
    "            rating = None if not(\"employer_rating\" in vacancy[\"employer\"]) else convert_with_checking(float, vacancy[\"employer\"][\"employer_rating\"], \"total_rating\")\n",
    "            reviews = None if not(\"employer_rating\" in vacancy[\"employer\"]) else convert_with_checking(int, vacancy[\"employer\"][\"employer_rating\"], \"reviews_count\")\n",
    "            log_url = vacancy[\"employer\"][\"logo_urls\"][\"original\"] if vacancy[\"employer\"][\"logo_urls\"] else None\n",
    "            if not employer[1] and rating:\n",
    "                employer[1] = rating\n",
    "            if not employer[2] and reviews:\n",
    "                employer[2] = reviews\n",
    "            if not employer[5] and log_url:\n",
    "                employer[5] = log_url\n",
    "                    \n",
    "employers = [[key] + value for key, value in employers.items()]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522fc6ef-953e-41ff-845f-7ae6ad428efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "vacancies_column_names = [\n",
    "    'id',\n",
    "    'area',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'archived',\n",
    "    'created_at',\n",
    "    'published_at',\n",
    "    'has_test',\n",
    "    'internship',\n",
    "    'salary_from',\n",
    "    'salary_to',\n",
    "    'salary_frequency',\n",
    "    'company_id',\n",
    "    'experience',\n",
    "    'employment'\n",
    "]\n",
    "employers_column_names = [\n",
    "    'id',\n",
    "    'name',\n",
    "    'total_rating',\n",
    "    'reviews_count',\n",
    "    'accredited_it_employer',\n",
    "    'trusted',\n",
    "    'logo_url'\n",
    "]\n",
    "vacancy_roles_column_names = [\n",
    "    'vacancy_id',\n",
    "    'role_id'\n",
    "]\n",
    "vacancy_work_formats_column_names = [\n",
    "    'vacancy_id',\n",
    "    'work_format'\n",
    "]\n",
    "\n",
    "\n",
    "vacancies_df = pd.DataFrame(vacancy_data, columns=vacancies_column_names)\n",
    "vacancies_df.drop_duplicates(subset=[\"id\"], keep=\"first\", inplace=True)\n",
    "\n",
    "employers_df = pd.DataFrame(employers, columns=employers_column_names)\n",
    "\n",
    "vacancy_roles_df = pd.DataFrame(vacancy_role, columns=vacancy_roles_column_names)\n",
    "vacancy_roles_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "vacancy_work_formats_df = pd.DataFrame(vacancy_work_formats, columns=vacancy_work_formats_column_names)\n",
    "vacancy_work_formats_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49616fb-a813-4dc2-ba95-38140eb0ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Обработка null значений с вакансии\n",
      "[#] До обработки\n",
      "[-] Общее количество записей: 6088\n",
      "[-] Количество null значений в vacancies_df:\n",
      "id                     0\n",
      "area                   0\n",
      "latitude            2259\n",
      "longitude           2259\n",
      "archived               0\n",
      "created_at             0\n",
      "published_at           0\n",
      "has_test               0\n",
      "internship             0\n",
      "salary_from         3370\n",
      "salary_to           4428\n",
      "salary_frequency       0\n",
      "company_id             0\n",
      "experience             0\n",
      "employment             0\n",
      "dtype: int64\n",
      "[-] Количество null значений с salary_from или salary_from & salary_to: 3370\n",
      "[&] Удаляем вакансии с salary_from == null или salary_from & salary_to == null...\n",
      "[&] Заполняем долготу и широту по названию региона...\n",
      "[-] Количество ненайденных местностей: 1\n",
      "[-] Сбрасываем их. Количество сброшенных строк: 138\n",
      "[&] Меняем null...\n",
      "[#] После обработки\n",
      "[-] Общее количество записей: 2580\n",
      "id                     0\n",
      "area                   0\n",
      "latitude               0\n",
      "longitude              0\n",
      "archived               0\n",
      "created_at             0\n",
      "published_at           0\n",
      "has_test               0\n",
      "internship             0\n",
      "salary_from            0\n",
      "salary_to           1336\n",
      "salary_frequency       0\n",
      "company_id             0\n",
      "experience             0\n",
      "employment             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"[#] Обработка null значений с вакансии\")\n",
    "print(\"[#] До обработки\")\n",
    "\n",
    "print(f\"[-] Общее количество записей: {vacancies_df['id'].count()}\")\n",
    "print(\"[-] Количество null значений в vacancies_df:\")\n",
    "print(vacancies_df.isnull().sum())\n",
    "\n",
    "nulls_id = vacancies_df[\n",
    "    vacancies_df['salary_from'].isnull() | (vacancies_df['salary_from'].isnull() & vacancies_df['salary_to'].isnull())\n",
    "][\"id\"].copy()\n",
    "print(f\"[-] Количество null значений с salary_from или salary_from & salary_to: {len(nulls_id.index)}\")\n",
    "print(\"[&] Удаляем вакансии с salary_from == null или salary_from & salary_to == null...\")\n",
    "vacancies_df.drop(nulls_id.index, inplace=True)\n",
    "\n",
    "print(\"[&] Заполняем долготу и широту по названию региона...\")\n",
    "areas_to_fix = vacancies_df[vacancies_df['longitude'].isnull()][\"area\"].unique()\n",
    "\n",
    "cursor.execute(\"SELECT name, latitude, longitude FROM area_coordinates\")\n",
    "\n",
    "coordinates = {area[0]: [float(area[1]), float(area[2])] for area in cursor.fetchall()}\n",
    "new_coordinates = {}\n",
    "for area in areas_to_fix:\n",
    "    if not(coordinates.get(area, [])):\n",
    "        getLoc = loc.geocode(area)\n",
    "        if getLoc:\n",
    "            latitude = getLoc.latitude\n",
    "            longitude = getLoc.longitude\n",
    "            coordinates[area] = [latitude, longitude]\n",
    "            new_coordinates[area] = [latitude, longitude]\n",
    "\n",
    "if new_coordinates:\n",
    "    with open(\"add_new_coordinates.sql\", \"w\") as file:\n",
    "        file.write(\"INSERT INTO area_coordinates (name, latitude, longitude) VALUES\\n\")\n",
    "        file.write(\n",
    "            \",\\n\".join(\n",
    "                [\n",
    "                    f\"('{name}', {latitude}, {longtitude})\"\n",
    "                    for (name, (latitude, longtitude)) in new_coordinates.items()\n",
    "                ]\n",
    "            ) + \";\"\n",
    "        )\n",
    "\n",
    "have_null_areas = False\n",
    "\n",
    "if len(coordinates.keys()) == len(areas_to_fix):\n",
    "    print(\"[&] Есть все координаты, меняем null...\")\n",
    "else:\n",
    "    print(f\"[-] Количество ненайденных местностей: {len(areas_to_fix) - len(coordinates)}\")\n",
    "    print(f\"[-] Сбрасываем их.\", end=\" \")\n",
    "    have_null_areas = True\n",
    "    null_areas = vacancies_df[\n",
    "        ~vacancies_df['area'].isin(coordinates.keys())\n",
    "    ][\"id\"].copy()\n",
    "    vacancies_df.drop(null_areas.index, inplace=True)\n",
    "    print(f\"Количество сброшенных строк: {len(null_areas.index)}\")\n",
    "    print(\"[&] Меняем null...\")\n",
    "\n",
    "vacancies_df.loc[:, ['latitude', 'longitude']] = vacancies_df[\"area\"].apply(lambda x: coordinates[x]).values.tolist()\n",
    "\n",
    "print(\"[#] После обработки\")\n",
    "print(f\"[-] Общее количество записей: {vacancies_df[\"id\"].count()}\")\n",
    "print(vacancies_df.isnull().sum())\n",
    "\n",
    "nulls_id = sorted(nulls_id.values.tolist() + null_areas.values.tolist()) if have_null_areas else sorted(nulls_id.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84495977-8508-4cc5-ba40-33acfea368d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Удалим данные связанные с удаленными вакансиями\n",
    "dropping_vacancy_roles_index = vacancy_roles_df[vacancy_roles_df[\"vacancy_id\"].isin(nulls_id)].index\n",
    "vacancy_roles_df.drop(dropping_vacancy_roles_index, inplace=True)\n",
    "\n",
    "dropping_vacancy_work_formats_index = vacancy_work_formats_df[vacancy_work_formats_df[\"vacancy_id\"].isin(nulls_id)].index\n",
    "vacancy_work_formats_df.drop(dropping_vacancy_work_formats_index, inplace=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21417fd-1b9f-4792-aba2-ccbf11c56f9e",
   "metadata": {},
   "source": [
    "### Выделение технических навыков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe15190-763a-483f-a6ab-e7f4221c75cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vacancy_ids = vacancies_df[\"id\"].values\n",
    "result = []\n",
    "i = 0\n",
    "problem_ids = []\n",
    "while i != len(vacancy_ids):\n",
    "    response = requests.get(f\"https://api.hh.ru/vacancies/{vacancy_ids[i]}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        segmented_description = extract_requirements_segment(data[\"description\"]).lower()\n",
    "        for skill in data[\"key_skills\"]:\n",
    "            if len(skill) <= 45 and len(skill.split()) <= 3:\n",
    "                skills.add(skill.lower())\n",
    "        result.append((vacancy_ids[i], segmented_description))\n",
    "    elif response.status_code == 404:\n",
    "        problem_ids.append(id)\n",
    "    else:\n",
    "        print(f\"Captcha at {i}'s request. Sleeping 10 seconds\")\n",
    "        time.sleep(10)\n",
    "        continue\n",
    "    if i % 100 == 0:\n",
    "        print(i, \"Done\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97686f0-b10d-462f-8d86-abbed734158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is not new skills\n"
     ]
    }
   ],
   "source": [
    "# Добавляем новые скилы при необходимости\n",
    "new_skills = parsing_skills.difference(skills)\n",
    "if len(new_skills) != 0:\n",
    "    print(\"creating sql file\")\n",
    "    with open(\"add_new_skills.sql\", 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(\"insert into skills values\\n\")\n",
    "        file.write(\",\\n\".join([f\"('{skill}')\" for skill in new_skills]) + \";\")\n",
    "else:\n",
    "    print(\"there is not new skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa3a5bd7-4411-4cb7-9f48-a61122478349",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_to_save = []\n",
    "for description, skills in result:\n",
    "    skills_to_save.append({\"description\": description, \"skills\": skills})\n",
    "to_save = {\"items\": skills_to_save}\n",
    "with open(\"json_results/skills_data.json\", 'w', encoding='utf-16') as file:\n",
    "    json.dump(to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0dab4e-d047-42cb-ae5b-8f65fe0c306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"json_results/skills_data.json\", 'r', encoding='utf-16')\n",
    "vacancy_descriptions = json.loads(file.read())[\"items\"]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13c744f-5ea4-45d9-88d9-a685ae89fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6324bef-8f69-4a02-8320-4b79d56f7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_ru = set(stopwords.words('russian'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "skills_in_model = [s for s in tech_skills if s.lower() in model]\n",
    "\n",
    "all_stop_words = stop_words_en | stop_words_ru | punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8b7ff1-afc2-47ad-a998-4983ee0434e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_skills(vacancies_id, text, skills_in_model):\n",
    "    vacancy = extracted.lower()\n",
    "    \n",
    "    tokens = [t for t in word_tokenize(vacancy) if t in model]\n",
    "    \n",
    "    tokens = [t for t in tokens if t.lower() not in all_stop_words and t.strip() != '']\n",
    "\n",
    "    token_matrix = np.array([model[t] for t in tokens])\n",
    "    skill_matrix = np.array([model[s.lower()] for s in skills_in_model])\n",
    "\n",
    "    similarities = cosine_similarity(token_matrix, skill_matrix)\n",
    "\n",
    "    found_skills = {skills_in_model[j]\n",
    "                    for i in range(len(tokens))\n",
    "                    for j in range(len(skills_in_model))\n",
    "                    if similarities[i, j] > 0.85}\n",
    "    \n",
    "    return [(vacancies_id, tech_skills[skill]) for skill in found_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88931a40-cf75-4ce8-94a0-031db10b6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_skills = []\n",
    "for description in vacancy_descriptions:\n",
    "    vacancy_skills += get_vacancy_skills(description[0], description[1], skills_in_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
